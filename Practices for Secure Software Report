Practices for Secure Software Report

 
Table of Contents
DOCUMENT REVISION HISTORY	3
CLIENT	3
INSTRUCTIONS	ERROR! BOOKMARK NOT DEFINED.
DEVELOPER	4
1. ALGORITHM CIPHER	4
2. CERTIFICATE GENERATION	4
3. DEPLOY CIPHER	6
4. SECURE COMMUNICATIONS	6
5. SECONDARY TESTING	7
6. FUNCTIONAL TESTING	7
7. SUMMARY	8
8. INDUSTRY STANDARD BEST PRACTICES	8

 
Document Revision History

Version	Date	Author	Comments
1.0	8/11/2025	John Chomen	

Client

Developer
John C.

Algorithm Cipher

Recommendation: SHA‑256 (SHA‑2 family) as the checksum algorithm for file/data verification.

Overview: SHA‑256 is a one‑way cryptographic hash function that maps arbitrary‑length input to a fixed 256‑bit output. It is designed for collision resistance and preimage resistance—critical for detecting tampering during file transfer.

Hash & bit level: 256‑bit digest (64 hex chars). Higher bit length increases brute‑force work factor compared to MD5/SHA‑1.

Randomness & keys: Pure hashes (like SHA‑256) do not use random numbers or keys. For authenticated integrity over an untrusted channel, use HMAC‑SHA‑256 with a shared secret. For transport security and server authentication, rely on TLS (X.509 certificates) rather than embedding keys in the application.

Symmetric vs asymmetric: TLS uses asymmetric crypto (X.509/PKI) to establish identity and session keys; payload integrity within the tunnel uses symmetric MACs. Within the application, SHA‑256 provides deterministic checksums for stored/transferred artifacts. If you need tamper‑evident application‑level integrity, prefer HMAC‑SHA‑256.

History & current state: Older hashes MD5 and SHA‑1 are broken for collision resistance and must not be used. SHA‑2 (SHA‑256/384/512) remains widely recommended, and SHA‑3 exists as an alternative. SHA‑256 balances security, interoperability, and performance and is supported natively by Java (MessageDigest).

Certificate Generation
 
Summary

Following the Vulnerability Assessment Process Flow Diagram, I implemented secure software design principles across critical areas of the application. I began by conducting a targeted review of the controller layer, where I refactored the ServerController.java class to integrate SHA-256 checksum generation. This provided a reliable method for detecting tampering in data transmitted or stored by the system. I also addressed the application's transport layer security by configuring HTTPS using a self-signed X.509 certificate and updating the Spring Boot application.properties file to enforce encrypted communication over port 8443. This ensured data confidentiality during client-server interactions.

In reviewing the application’s architecture, I verified that the RESTful structure followed secure design conventions and did not expose private data or internal logic through its endpoints. I performed functional testing to confirm that all added logic executed correctly and without runtime or syntax errors. To ensure that the refactored code did not introduce any new vulnerabilities, I integrated the OWASP Dependency-Check plugin into the Maven build process. The tool revealed existing critical vulnerabilities in several third-party dependencies, including spring-context, jackson-databind, and hibernate-validator. However, these were not introduced by my changes and would require broader library upgrades for full mitigation. Overall, the refactored code was validated both functionally and through static analysis, and it aligns with secure coding protocols required by the assignment.

Industry Standard Best Practices

Throughout the course of this project, I applied recognized industry standard best practices to ensure secure software development. For data integrity, I selected SHA-256, a member of the SHA-2 cryptographic hash family, due to its strong collision resistance and widespread adoption across modern systems. The checksum implementation ensures that the integrity of input data can be verified reliably, helping detect tampering or corruption during storage or transmission. To protect communications, I implemented HTTPS using Java’s Keytool to generate a self-signed certificate and configured TLS in the application to encrypt all data in transit.
I also addressed dependency-level security by incorporating the OWASP Dependency-Check plugin into the Maven build lifecycle. This approach reflects current DevSecOps practices, where automated tools are integrated early into the software development pipeline to identify and track known vulnerabilities in third-party components. Additionally, I followed the principle of secure defaults by leveraging secure keystore formats, enabling HTTPS by default, and minimizing the surface area of the application by only exposing essential endpoints and functionality.
By adhering to these practices, the refactored application reduces risk and improves resilience against common attack vectors. These improvements directly contribute to the software’s long-term stability, audit readiness, and ability to handle sensitive financial data on behalf of Artemis Financial. The use of cryptographic controls, encrypted transport, and automated security checks demonstrates a layered approach to security, which is essential in today’s threat landscape and supports the organization’s commitment to protecting client data.

